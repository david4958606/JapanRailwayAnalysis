{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8a3180562da5e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:33:22.820351Z",
     "start_time": "2024-11-20T15:33:22.592627Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "LINES = r'data/line20240426.csv'\n",
    "STATIONS = r'data/station20240426.csv'\n",
    "\n",
    "JOIN = r'data/join20240426.csv'\n",
    "\n",
    "JR_LINES = r'data/jr_lines.csv'\n",
    "JR_STATIONS = r'data/jr_stations.csv'\n",
    "\n",
    "SHINKANSEN_LINES = r'data/shinkansen_lines.csv'\n",
    "SHINKANSEN_STATIONS = r'data/shinkansen_stations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432ba5182f0baf19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:33:22.839362Z",
     "start_time": "2024-11-20T15:33:22.823360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select all stations called '東京'\n",
    "with open(STATIONS, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Skip the header row\n",
    "    header = next(reader)\n",
    "\n",
    "    # Open the output CSV file once before the loop\n",
    "    with open('data/tokyo.csv', 'w', encoding='utf-8', newline='') as f1:\n",
    "        writer = csv.writer(f1)\n",
    "\n",
    "        # Write the header to the output file\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Iterate over rows and write matching rows to the output\n",
    "        for row in reader:\n",
    "            if '東京' in row[2]:  # Check if '東京' is in station_name\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a93885e1a79a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:33:22.889493Z",
     "start_time": "2024-11-20T15:33:22.884985Z"
    }
   },
   "outputs": [],
   "source": [
    "# select JR lines\n",
    "with open(LINES, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Skip the header row\n",
    "    header = next(reader)\n",
    "\n",
    "    # Open the output CSV file once before the loop\n",
    "    with open('data/jr_lines.csv', 'w', encoding='utf-8', newline='') as f1:\n",
    "        writer = csv.writer(f1)\n",
    "\n",
    "        # Write the header to the output file\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Iterate over rows and write matching rows to the output\n",
    "        for row in reader:\n",
    "            if row[1] in ('1', '2', '3', '4', '5', '6'): # JR ID\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bccacc3c19840e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:33:22.897800Z",
     "start_time": "2024-11-20T15:33:22.894796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read JR line_cd\n",
    "\n",
    "jr_lines = []\n",
    "\n",
    "with open(JR_LINES, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        jr_lines.append(row[0])\n",
    "\n",
    "# print(jr_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17906552c824995b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:33:22.963668Z",
     "start_time": "2024-11-20T15:33:22.911648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select all stations on JR lines\n",
    "with open(STATIONS, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Skip the header row\n",
    "    header = next(reader)\n",
    "    # print(header)\n",
    "\n",
    "    # Open the output CSV file once before the loop\n",
    "    with open(JR_STATIONS, 'w+', encoding='utf-8', newline='') as f1:\n",
    "        writer = csv.writer(f1)\n",
    "        # print(\"data/jr_stations.csv\")\n",
    "\n",
    "        # Write the header to the output file\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Iterate over rows and write matching rows to the output\n",
    "        for row in reader:\n",
    "            if row[5] in jr_lines:  # Check if line_cd is in jr_lines\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "388cf3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001', '1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012']\n"
     ]
    }
   ],
   "source": [
    "# Read SHINKANSEN line_cd\n",
    "\n",
    "shinkansen_lines = []\n",
    "\n",
    "with open(SHINKANSEN_LINES, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        shinkansen_lines.append(row[0])\n",
    "\n",
    "print(shinkansen_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ace0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all stations on SHINKANSEN lines\n",
    "with open(STATIONS, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Skip the header row\n",
    "    header = next(reader)\n",
    "    # print(header)\n",
    "\n",
    "    # Open the output CSV file once before the loop\n",
    "    with open(SHINKANSEN_STATIONS, 'w+', encoding='utf-8', newline='') as f1:\n",
    "        writer = csv.writer(f1)\n",
    "\n",
    "        # Write the header to the output file\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Iterate over rows and write matching rows to the output\n",
    "        for row in reader:\n",
    "            if row[5] in shinkansen_lines:  # Check if line_cd is in jr_lines\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dabba706424c17b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:43:23.938271Z",
     "start_time": "2024-11-20T15:43:23.808656Z"
    }
   },
   "outputs": [],
   "source": [
    "# JR 车站对线路字典\n",
    "import json\n",
    "\n",
    "stations_df = pd.read_csv(JR_STATIONS)\n",
    "lines_df = pd.read_csv(JR_LINES)\n",
    "output_csv = 'data/jr_stations_lines.csv'\n",
    "output_json = 'data/jr_stations_lines.json'\n",
    "\n",
    "# 合并数据，以 line_cd 作为键\n",
    "merged_df = pd.merge(stations_df, lines_df, on='line_cd', how='inner')\n",
    "# 选择需要的列：车站名称和线路名称\n",
    "result_df = merged_df[['station_name', 'line_name']]\n",
    "result_df.to_csv(output_csv, index=False)\n",
    "\n",
    "station_lines_dict = {}\n",
    "for _, row in result_df.iterrows():\n",
    "    station_name = row['station_name']\n",
    "    line_name = row['line_name']\n",
    "    if station_name not in station_lines_dict:\n",
    "        station_lines_dict[station_name] = []\n",
    "    station_lines_dict[station_name].append(line_name)\n",
    "\n",
    "station_lines_list = []\n",
    "\n",
    "for station, lines in station_lines_dict.items():\n",
    "    station_lines_list.append({\n",
    "        'station': station,\n",
    "        'lines': lines\n",
    "    })\n",
    "\n",
    "with open(output_json, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(station_lines_list, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcacc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JR 线路对车站字典\n",
    "line_stations_dict = {}\n",
    "for _, row in result_df.iterrows():\n",
    "    station_name = row['station_name']\n",
    "    line_name = row['line_name']\n",
    "    if line_name not in line_stations_dict:\n",
    "        line_stations_dict[line_name] = []\n",
    "    line_stations_dict[line_name].append(station_name)\n",
    "\n",
    "line_stations_list = []\n",
    "for line, stations in line_stations_dict.items():\n",
    "    line_stations_list.append({\n",
    "        'line': line,\n",
    "        'stations': stations\n",
    "    })\n",
    "\n",
    "output_json = 'data/jr_lines_stations.json'\n",
    "with open(output_json, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(line_stations_list, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新干线车站对线路字典\n",
    "import json\n",
    "\n",
    "stations_df = pd.read_csv(SHINKANSEN_STATIONS)\n",
    "lines_df = pd.read_csv(SHINKANSEN_LINES)\n",
    "output_csv = 'data/shinkansen_stations_lines.csv'\n",
    "output_json = 'data/shinkansen_stations_lines.json'\n",
    "\n",
    "# 合并数据，以 line_cd 作为键\n",
    "merged_df = pd.merge(stations_df, lines_df, on='line_cd', how='inner')\n",
    "# 选择需要的列：车站名称和线路名称\n",
    "result_df = merged_df[['station_name', 'line_name']]\n",
    "result_df.to_csv(output_csv, index=False)\n",
    "\n",
    "station_lines_dict = {}\n",
    "for _, row in result_df.iterrows():\n",
    "    station_name = row['station_name']\n",
    "    line_name = row['line_name']\n",
    "    if station_name not in station_lines_dict:\n",
    "        station_lines_dict[station_name] = []\n",
    "    station_lines_dict[station_name].append(line_name)\n",
    "\n",
    "station_lines_list = []\n",
    "\n",
    "for station, lines in station_lines_dict.items():\n",
    "    station_lines_list.append({\n",
    "        'station': station,\n",
    "        'lines': lines\n",
    "    })\n",
    "\n",
    "with open(output_json, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(station_lines_list, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c223d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新干线线路对车站字典\n",
    "line_stations_dict = {}\n",
    "for _, row in result_df.iterrows():\n",
    "    station_name = row['station_name']\n",
    "    line_name = row['line_name']\n",
    "    if line_name not in line_stations_dict:\n",
    "        line_stations_dict[line_name] = []\n",
    "    line_stations_dict[line_name].append(station_name)\n",
    "\n",
    "line_stations_list = []\n",
    "for line, stations in line_stations_dict.items():\n",
    "    line_stations_list.append({\n",
    "        'line': line,\n",
    "        'stations': stations\n",
    "    })\n",
    "\n",
    "output_json = 'data/shinkansen_lines_stations.json'\n",
    "with open(output_json, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(line_stations_list, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10bd156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new shinkansen_join CSV file\n",
    "join_df = pd.read_csv(JOIN)\n",
    "filtered_df = join_df[(join_df['line_cd'] >= 1002) & (join_df['line_cd'] <= 1012)]\n",
    "filtered_df.to_csv('data/shinkansen_join.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7738c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df = pd.read_csv(SHINKANSEN_LINES)\n",
    "\n",
    "# Merge the filtered join dataframe with the line dataframe to get line_name\n",
    "merged_df = filtered_df.merge(line_df[['line_cd', 'line_name']], on='line_cd', how='left')\n",
    "\n",
    "# Replace line_cd column with line_name\n",
    "merged_df = merged_df.drop(columns=['line_cd'])\n",
    "merged_df.rename(columns={'line_name': 'line_name'}, inplace=True)\n",
    "merged_df.to_csv('data/shinkansen_join.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0957a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the station CSV file\n",
    "station_df = pd.read_csv(SHINKANSEN_STATIONS)\n",
    "\n",
    "# Merge the updated join dataframe with the station dataframe to get station_name for station_cd1\n",
    "merged_df = merged_df.merge(station_df[['station_cd', 'station_name']], left_on='station_cd1', right_on='station_cd', how='left')\n",
    "\n",
    "# Replace station_cd1 column with station_name\n",
    "merged_df = merged_df.drop(columns=['station_cd1', 'station_cd'])\n",
    "merged_df.rename(columns={'station_name': 'station_name_1'}, inplace=True)\n",
    "merged_df.to_csv('data/shinkansen_join.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c39de77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the station CSV file\n",
    "station_df = pd.read_csv(SHINKANSEN_STATIONS)\n",
    "\n",
    "# Merge the updated join dataframe with the station dataframe to get station_name for station_cd1\n",
    "merged_df = merged_df.merge(station_df[['station_cd', 'station_name']], left_on='station_cd2', right_on='station_cd', how='left')\n",
    "\n",
    "# Replace station_cd1 column with station_name\n",
    "merged_df = merged_df.drop(columns=['station_cd2', 'station_cd'])\n",
    "merged_df.rename(columns={'station_name': 'station_name_2'}, inplace=True)\n",
    "merged_df.to_csv('data/shinkansen_join.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Iterate over the rows in the dataframe to add edges\n",
    "for _, row in merged_df.iterrows():\n",
    "    # Add an edge between the two stations (nodes) along the line\n",
    "    G.add_edge(row['station_name_1'], row['station_name_2'], line_name=row['line_name'])\n",
    "\n",
    "# Display information about the created graph\n",
    "print(nx.info(G))\n",
    "\n",
    "# Draw the graph for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G)  # Positioning nodes in a visually appealing way\n",
    "nx.draw(G, pos, with_labels=True, node_size=500, font_size=8, font_color='black', edge_color='gray')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): d['line_name'] for u, v, d in G.edges(data=True)}, font_size=7)\n",
    "\n",
    "plt.title('Railway Network Graph')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JapanRailwayAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
